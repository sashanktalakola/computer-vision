{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cadece8-5ba0-467e-94a1-c3ffca5b4b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a340fcde-930e-4a0e-af1e-e1078c3793e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SELayer(nn.Module):\n",
    "    def __init__(self, channels, reduction=4):\n",
    "        super(SELayer, self).__init__()\n",
    "        self.fc1 = nn.Linear(channels, channels // reduction, bias=False)\n",
    "        self.fc2 = nn.Linear(channels // reduction, channels, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, channels, height, width = x.size()\n",
    "        y = F.adaptive_avg_pool2d(x, (1, 1)).view(batch_size, channels)\n",
    "        y = F.relu(self.fc1(y))\n",
    "        y = torch.sigmoid(self.fc2(y)).view(batch_size, channels, 1, 1)\n",
    "        return x * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a770e8-5dc8-4e09-bf01-bc6eca7af92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, expand_ratio, use_se=False):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.expand_ratio = expand_ratio\n",
    "        self.use_se = use_se\n",
    "\n",
    "        self.expand = nn.Conv2d(in_channels, in_channels * expand_ratio, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels * expand_ratio)\n",
    "        self.relu = nn.SiLU()  # Swish activation\n",
    "\n",
    "        self.depthwise = nn.Conv2d(in_channels * expand_ratio, in_channels * expand_ratio, \n",
    "                                    kernel_size=kernel_size, stride=stride, padding=kernel_size // 2, groups=in_channels * expand_ratio)\n",
    "        self.bn2 = nn.BatchNorm2d(in_channels * expand_ratio)\n",
    "\n",
    "        self.project = nn.Conv2d(in_channels * expand_ratio, out_channels, kernel_size=1)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        if self.use_se:\n",
    "            self.se = SELayer(in_channels * expand_ratio)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        x = self.expand(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.depthwise(x)\n",
    "        x = self.bn2(x)\n",
    "\n",
    "        if self.use_se:\n",
    "            x = self.se(x)\n",
    "\n",
    "        x = self.project(x)\n",
    "        x = self.bn3(x)\n",
    "\n",
    "        return x + identity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1d543e-3337-4601-aee8-297a270befb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70583128-4e6c-4a13-830f-727653056584",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNetBackbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EfficientNetBackbone, self).__init__()\n",
    "        \n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "\n",
    "        self.blocks = nn.ModuleList([\n",
    "            # MBConv Block: (in_channels, out_channels, kernel_size, stride, expand_ratio, use_se)\n",
    "            ConvBlock(32, 16, kernel_size=3, stride=1, expand_ratio=1, use_se=False),\n",
    "            ConvBlock(16, 24, kernel_size=3, stride=2, expand_ratio=6, use_se=False),\n",
    "            ConvBlock(24, 24, kernel_size=3, stride=1, expand_ratio=6, use_se=False),\n",
    "            ConvBlock(24, 40, kernel_size=5, stride=2, expand_ratio=6, use_se=True),\n",
    "            ConvBlock(40, 40, kernel_size=5, stride=1, expand_ratio=6, use_se=True),\n",
    "            ConvBlock(40, 80, kernel_size=3, stride=2, expand_ratio=6, use_se=False),\n",
    "            ConvBlock(80, 80, kernel_size=3, stride=1, expand_ratio=6, use_se=False),\n",
    "            ConvBlock(80, 80, kernel_size=3, stride=1, expand_ratio=6, use_se=False),\n",
    "            ConvBlock(80, 112, kernel_size=5, stride=1, expand_ratio=6, use_se=True),\n",
    "            ConvBlock(112, 112, kernel_size=5, stride=1, expand_ratio=6, use_se=True),\n",
    "            ConvBlock(112, 192, kernel_size=3, stride=2, expand_ratio=6, use_se=False),\n",
    "            ConvBlock(192, 192, kernel_size=3, stride=1, expand_ratio=6, use_se=False),\n",
    "            ConvBlock(192, 192, kernel_size=3, stride=1, expand_ratio=6, use_se=False),\n",
    "            ConvBlock(192, 192, kernel_size=3, stride=1, expand_ratio=6, use_se=False),\n",
    "            ConvBlock(192, 192, kernel_size=3, stride=1, expand_ratio=6, use_se=False),\n",
    "            ConvBlock(192, 320, kernel_size=1, stride=1, expand_ratio=6, use_se=True),\n",
    "        ])\n",
    "\n",
    "        self.final_conv = nn.Conv2d(320, 1280, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        \n",
    "        feature_maps = []\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "            \n",
    "            if len(feature_maps) in [1, 3, 5, 10]: #Feature map stages\n",
    "                feature_maps.append(x)\n",
    "        \n",
    "        x = self.final_conv(x)\n",
    "        feature_maps.append(x)\n",
    "        \n",
    "        return feature_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119a00d5-a798-44a0-9623-3b74dd272896",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c9d385-a973-4e8b-b54e-b00482924b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopDownPathway(nn.Module):\n",
    "    def __init__(self, out_channels):\n",
    "        super(TopDownPathway, self).__init__()\n",
    "        self.fusion_conv = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, P3, P4, P5, P6):\n",
    "        P6_up = F.interpolate(P6, size=P5.shape[2:], mode='nearest')\n",
    "        P5 = P5 + P6_up\n",
    "        P5 = self.fusion_conv(P5)\n",
    "\n",
    "        P5_up = F.interpolate(P5, size=P4.shape[2:], mode='nearest')\n",
    "        P4 = P4 + P5_up\n",
    "        P4 = self.fusion_conv(P4)\n",
    "\n",
    "        P4_up = F.interpolate(P4, size=P3.shape[2:], mode='nearest')\n",
    "        P3 = P3 + P4_up\n",
    "        P3 = self.fusion_conv(P3)\n",
    "\n",
    "        return P3, P4, P5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de36840-118d-4f02-926a-0882db5d9d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BottomUpPathway(nn.Module):\n",
    "    def __init__(self, out_channels):\n",
    "        super(BottomUpPathway, self).__init__()\n",
    "        self.fusion_conv = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, P3, P4, P5):\n",
    "        P3_down = F.max_pool2d(P3, kernel_size=3, stride=2, padding=1)\n",
    "        P4 = P4 + P3_down\n",
    "        P4 = self.fusion_conv(P4)\n",
    "\n",
    "        P4_down = F.max_pool2d(P4, kernel_size=3, stride=2, padding=1)\n",
    "        P5 = P5 + P4_down\n",
    "        P5 = self.fusion_conv(P5)\n",
    "\n",
    "        return P4, P5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6acee-9c96-41cd-8b9e-bf45479aa147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daa1d6d-e6b6-4410-9649-661fe45ae81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiFPNLayer(nn.Module):\n",
    "    def __init__(self, out_channels):\n",
    "        super(BiFPNLayer, self).__init__()\n",
    "        self.top_down_pathway = TopDownPathway(out_channels)\n",
    "        self.bottom_up_pathway = BottomUpPathway(out_channels)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        P3, P4, P5, P6 = inputs\n",
    "\n",
    "        # Top-Down Pathway\n",
    "        P3, P4, P5 = self.top_down_pathway(P3, P4, P5, P6)\n",
    "        \n",
    "        # Bottom-Up Pathway\n",
    "        P4, P5 = self.bottom_up_pathway(P3, P4, P5)\n",
    "\n",
    "        return P3, P4, P5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581329ca-287f-4b8d-ada8-1847c0f6560e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc3c552-4fdc-4e90-b9d1-b0309455d869",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionHead(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes, num_anchors):\n",
    "        super(DetectionHead, self).__init__()\n",
    "        \n",
    "        # Shared convolutions\n",
    "        self.shared_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # Box regression head\n",
    "        self.box_head = nn.Conv2d(in_channels, num_anchors * 4, kernel_size=1)  # 4 coordinates per box\n",
    "\n",
    "        # Class prediction head\n",
    "        self.class_head = nn.Conv2d(in_channels, num_anchors * num_classes, kernel_size=1)  # num_classes per box\n",
    "\n",
    "        # Objectness score head\n",
    "        self.obj_head = nn.Conv2d(in_channels, num_anchors * 1, kernel_size=1)  # 1 score per box\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass through shared convolutions\n",
    "        x = self.shared_conv(x)\n",
    "\n",
    "        # Predict boxes, classes, and objectness scores\n",
    "        box_preds = self.box_head(x)\n",
    "        class_preds = self.class_head(x)\n",
    "        obj_preds = self.obj_head(x)\n",
    "\n",
    "        return box_preds, class_preds, obj_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b89109-940a-43c3-b9e5-42797773d324",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd0ba24-f27e-413f-bf5c-a31e35b08b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientDet(nn.Module):\n",
    "    def __init__(self, num_classes, num_anchors):\n",
    "        super(EfficientDet, self).__init__()\n",
    "\n",
    "        self.backbone = EfficientNetBackbone()\n",
    "\n",
    "        # BiFPN\n",
    "        self.bifpn = BiFPNLayer(out_channels=256)\n",
    "\n",
    "        # Detection Heads\n",
    "        self.detection_heads = nn.ModuleList([\n",
    "            DetectionHead(in_channels=256, num_classes=num_classes, num_anchors=num_anchors),\n",
    "            DetectionHead(in_channels=256, num_classes=num_classes, num_anchors=num_anchors),\n",
    "            DetectionHead(in_channels=256, num_classes=num_classes, num_anchors=num_anchors)\n",
    "        ])  # One head for each level of BiFPN output\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extract features from the backbone\n",
    "        feature_maps = self.backbone(x)\n",
    "\n",
    "        # Pass feature maps through BiFPN\n",
    "        bifpn_outputs = self.bifpn(feature_maps)\n",
    "\n",
    "        # Collect outputs from detection heads\n",
    "        outputs = []\n",
    "        for head, feature_map in zip(self.detection_heads, bifpn_outputs):\n",
    "            outputs.append(head(feature_map))\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cff62a-e24d-4c37-9d6d-311b36797065",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
