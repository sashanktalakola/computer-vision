{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb5e301-a29f-414b-9b3a-e7eb1a8366e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class YOLOv2(nn.Module):\n",
    "    def __init__(self, num_classes, anchors, grid_size=13, num_bboxes=5):\n",
    "        super(YOLOv2, self).__init__()\n",
    "\n",
    "        # Initialize Darknet-19 backbone\n",
    "        self.backbone = Darknet19() # implemented in darknet-19.ipynb\n",
    "\n",
    "        # Final detection layer: 1x1 convolution to predict bounding boxes and class probabilities\n",
    "        # Output channels are: (B * 5 + C), where B is number of bounding boxes per grid,\n",
    "        # 5 for (x, y, w, h, confidence), and C is number of classes.\n",
    "        self.det_conv = nn.Conv2d(1024, num_bboxes * (5 + num_classes), kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "        self.grid_size = grid_size\n",
    "        self.num_bboxes = num_bboxes\n",
    "        self.num_classes = num_classes\n",
    "        self.anchors = anchors  # List of anchor box dimensions\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass through the backbone to get feature map\n",
    "        x = self.backbone(x)\n",
    "\n",
    "        # Pass through the detection convolution layer\n",
    "        output = self.det_conv(x)\n",
    "\n",
    "        # Reshape the output to (batch_size, grid_size, grid_size, B*(5 + C))\n",
    "        output = output.view(output.size(0), self.num_bboxes * (5 + self.num_classes), self.grid_size, self.grid_size)\n",
    "\n",
    "        # Permute to (batch_size, grid_size, grid_size, B*(5 + C)) \n",
    "        # for easier access to bounding box parameters\n",
    "        output = output.permute(0, 2, 3, 1)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "    def predict(self, x, threshold=0.5):\n",
    "        \"\"\"\n",
    "        This method processes the network's output and applies Non-Maximum Suppression (NMS).\n",
    "        The output will be filtered based on the confidence score threshold.\n",
    "        \"\"\"\n",
    "        # Run the forward pass\n",
    "        output = self.forward(x)\n",
    "\n",
    "        # Output shape is (batch_size, grid_size, grid_size, B*(5 + C))\n",
    "        batch_size, grid_size, _, _ = output.shape\n",
    "\n",
    "        # Initialize the predictions\n",
    "        predictions = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            grid_pred = output[i]  # Shape: (grid_size, grid_size, B*(5 + C))\n",
    "\n",
    "            # Initialize list to store individual predictions for the current image\n",
    "            image_predictions = []\n",
    "\n",
    "            for j in range(grid_size):\n",
    "                for k in range(grid_size):\n",
    "                    cell_pred = grid_pred[j, k]  # Shape: (B*(5 + C),)\n",
    "                    \n",
    "                    # Reshape to (B, 5 + C)\n",
    "                    cell_pred = cell_pred.view(self.num_bboxes, 5 + self.num_classes)\n",
    "\n",
    "                    # Extract the box coordinates and confidence\n",
    "                    box_confidence = cell_pred[:, 4]\n",
    "                    box_coords = cell_pred[:, :4]  # x, y, w, h\n",
    "                    class_probs = cell_pred[:, 5:]  # Class probabilities\n",
    "\n",
    "                    # Apply sigmoid to box confidence and class probabilities\n",
    "                    box_confidence = torch.sigmoid(box_confidence)\n",
    "                    class_probs = torch.sigmoid(class_probs)\n",
    "\n",
    "                    # Filter out predictions based on confidence threshold\n",
    "                    mask = box_confidence > threshold\n",
    "                    box_confidence = box_confidence[mask]\n",
    "                    box_coords = box_coords[mask]\n",
    "                    class_probs = class_probs[mask]\n",
    "\n",
    "                    if len(box_confidence) > 0:\n",
    "                        # Each prediction is (confidence, bbox, class_probs)\n",
    "                        image_predictions.append((box_confidence, box_coords, class_probs))\n",
    "\n",
    "            predictions.append(image_predictions)\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5336acd-e103-4ccd-abca-69b3b030cba1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03ff048-513b-4ebc-bf28-8fe3037c626c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def yolo_loss(predictions, targets, anchors, num_classes, grid_size=13, num_bboxes=5, lambda_coord=5, lambda_noobj=0.5):\n",
    "    \"\"\"\n",
    "    Compute the YOLO v2 loss without using nn.Module.\n",
    "    \n",
    "    :param predictions: Tensor of shape (batch_size, grid_size, grid_size, B * (5 + C)), predicted outputs from the network\n",
    "    :param targets: Tensor of shape (batch_size, grid_size, grid_size, B * (5 + C)), ground truth values\n",
    "    :param anchors: List of anchor box sizes, e.g., [(116, 90), (156, 198), (373, 326)]\n",
    "    :param num_classes: Number of classes\n",
    "    :param grid_size: Size of the grid (S)\n",
    "    :param num_bboxes: Number of bounding boxes per grid cell (B)\n",
    "    :param lambda_coord: Scaling factor for bounding box loss\n",
    "    :param lambda_noobj: Scaling factor for \"no object\" confidence loss\n",
    "    :return: Total loss as a scalar tensor\n",
    "    \"\"\"\n",
    "    batch_size = predictions.size(0)\n",
    "    \n",
    "    # Reshape predictions and targets\n",
    "    predictions = predictions.view(batch_size, grid_size, grid_size, num_bboxes, 5 + num_classes)\n",
    "    targets = targets.view(batch_size, grid_size, grid_size, num_bboxes, 5 + num_classes)\n",
    "    \n",
    "    # Extract prediction components\n",
    "    pred_conf = predictions[..., 4]  # Predicted confidence scores\n",
    "    pred_boxes = predictions[..., :4]  # Predicted bounding box coordinates (x, y, w, h)\n",
    "    pred_class = predictions[..., 5:]  # Predicted class probabilities\n",
    "    \n",
    "    # Extract ground truth components\n",
    "    target_conf = targets[..., 4]  # Ground truth confidence\n",
    "    target_boxes = targets[..., :4]  # Ground truth bounding box coordinates\n",
    "    target_class = targets[..., 5:]  # Ground truth class labels\n",
    "\n",
    "    # Compute the losses\n",
    "    loss_conf = compute_confidence_loss(pred_conf, target_conf, target_boxes, lambda_noobj)\n",
    "    loss_coord = compute_coord_loss(pred_boxes, target_boxes, target_conf, lambda_coord)\n",
    "    loss_class = compute_class_loss(pred_class, target_class, target_conf)\n",
    "\n",
    "    # Total loss\n",
    "    total_loss = loss_conf + loss_coord + loss_class\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def compute_confidence_loss(pred_conf, target_conf, target_boxes, lambda_noobj):\n",
    "    \"\"\"\n",
    "    Confidence loss (binary cross-entropy).\n",
    "    \"\"\"\n",
    "    # Loss for \"object\" cells (those where target_conf == 1)\n",
    "    obj_mask = target_conf == 1\n",
    "    noobj_mask = target_conf == 0\n",
    "\n",
    "    # Compute confidence loss for objects and non-objects\n",
    "    obj_loss = F.binary_cross_entropy_with_logits(pred_conf[obj_mask], target_conf[obj_mask], reduction='sum')\n",
    "    noobj_loss = F.binary_cross_entropy_with_logits(pred_conf[noobj_mask], target_conf[noobj_mask], reduction='sum')\n",
    "\n",
    "    # Adjust no object loss by lambda_noobj\n",
    "    return obj_loss + lambda_noobj * noobj_loss\n",
    "\n",
    "\n",
    "def compute_coord_loss(pred_boxes, target_boxes, target_conf, lambda_coord):\n",
    "    \"\"\"\n",
    "    Coordinate loss for bounding box predictions (mean squared error).\n",
    "    \"\"\"\n",
    "    # Only compute loss for cells with object present (target_conf == 1)\n",
    "    mask = target_conf == 1\n",
    "\n",
    "    # MSE loss for bounding box coordinates (x, y, w, h)\n",
    "    coord_loss = F.mse_loss(pred_boxes[mask], target_boxes[mask], reduction='sum')\n",
    "    return lambda_coord * coord_loss\n",
    "\n",
    "\n",
    "def compute_class_loss(pred_class, target_class, target_conf):\n",
    "    \"\"\"\n",
    "    Classification loss (cross-entropy).\n",
    "    \"\"\"\n",
    "    # Only compute loss for cells with object present (target_conf == 1)\n",
    "    mask = target_conf == 1\n",
    "\n",
    "    # Reshape to make the target class a single dimension for cross entropy\n",
    "    target_class = target_class[mask].max(dim=-1)[1]  # Use max to get the class index\n",
    "    pred_class = pred_class[mask]  # Predicted class probabilities\n",
    "\n",
    "    # Cross-entropy loss for class predictions\n",
    "    class_loss = F.cross_entropy(pred_class.view(-1, pred_class.size(-1)), target_class.view(-1), reduction='sum')\n",
    "    return class_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e144eb5-e855-499a-bd2b-5afb69959320",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
