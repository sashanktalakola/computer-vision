{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528d1c4f-846d-49fa-9dea-d5cc7b335727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8992f384-2c36-45be-9a7d-afd1c15b6c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Backbone(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(Backbone, self).__init__()\n",
    "        \n",
    "        # Load a pretrained ResNet50 backbone from torchvision\n",
    "        resnet = models.resnet50(pretrained=pretrained)\n",
    "        \n",
    "        # Use layers before the fully connected layer (resnet.fc)\n",
    "        self.backbone = nn.Sequential(*list(resnet.children())[:-2])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Forward pass through the layers of the backbone, storing outputs at different stages\n",
    "        features = []\n",
    "        \n",
    "        # Pass through the layers of the backbone, storing outputs at different stages\n",
    "        for name, module in self.backbone.named_children():\n",
    "            x = module(x)\n",
    "            if name in ['4', '5', '6']:  # These are stages where features are produced\n",
    "                features.append(x)\n",
    "        \n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd05339-ee06-4aee-be94-bf32c5d65301",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopDownPathway(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(TopDownPathway, self).__init__()\n",
    "        \n",
    "        # List of convolutional layers to reduce the number of channels after each upsampling\n",
    "        self.lateral_convs = nn.ModuleList([nn.Conv2d(in_ch, out_channels, kernel_size=1) \n",
    "                                            for in_ch in in_channels])\n",
    "        \n",
    "    def forward(self, features):\n",
    "        \"\"\"\n",
    "        :param features: List of feature maps from the backbone network\n",
    "                         Each feature map in the list is of shape (batch_size, channels, height, width)\n",
    "        :return: List of feature maps after top-down aggregation.\n",
    "        \"\"\"\n",
    "        # Make sure the input list is ordered from shallowest to deepest\n",
    "        assert len(features) == len(self.lateral_convs)\n",
    "        \n",
    "        # Initialize the list to store the output of each stage\n",
    "        top_down_features = []\n",
    "        \n",
    "        # Start with the last (deepest) feature map\n",
    "        x = features[-1]\n",
    "        \n",
    "        # Iterate over the feature maps from deepest to shallowest\n",
    "        for i in range(len(features) - 2, -1, -1):\n",
    "            # Upsample the feature map\n",
    "            x = F.interpolate(x, size=features[i].shape[2:], mode='bilinear', align_corners=False)\n",
    "            \n",
    "            # Apply the lateral convolution to match the number of channels\n",
    "            lateral_x = self.lateral_convs[i](features[i])\n",
    "            \n",
    "            # Add the upsampled feature map to the current feature map\n",
    "            x = x + lateral_x\n",
    "            \n",
    "            # Append the processed feature map to the output list\n",
    "            top_down_features.append(x)\n",
    "        \n",
    "        # Reverse the list to maintain the order from shallowest to deepest\n",
    "        top_down_features.reverse()\n",
    "        \n",
    "        return top_down_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279c3efd-a0d1-433e-8173-d458d5563376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9125185e-ed0b-46f2-8582-f76339925dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BottomUpPathway(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        \"\"\"\n",
    "        :param in_channels: List of channel sizes for each level of feature maps.\n",
    "        :param out_channels: The desired number of output channels for the aggregated features.\n",
    "        \"\"\"\n",
    "        super(BottomUpPathway, self).__init__()\n",
    "        \n",
    "        # Lateral convolutions to reduce the number of channels after each upsampling\n",
    "        self.lateral_convs = nn.ModuleList([nn.Conv2d(in_ch, out_channels, kernel_size=1) \n",
    "                                            for in_ch in in_channels])\n",
    "\n",
    "    def forward(self, features):\n",
    "        \"\"\"\n",
    "        :param features: List of feature maps (from shallow to deep) passed through the network.\n",
    "        :return: List of feature maps after bottom-up aggregation.\n",
    "        \"\"\"\n",
    "        # Ensure the input list is ordered from shallowest to deepest\n",
    "        assert len(features) == len(self.lateral_convs)\n",
    "        \n",
    "        # Initialize the list to store the output of each stage\n",
    "        bottom_up_features = []\n",
    "        \n",
    "        # Start with the shallowest feature map\n",
    "        x = features[0]\n",
    "        \n",
    "        # Iterate over the feature maps from shallow to deep\n",
    "        for i in range(1, len(features)):\n",
    "            # Upsample the feature map\n",
    "            x = F.interpolate(x, size=features[i].shape[2:], mode='bilinear', align_corners=False)\n",
    "            \n",
    "            # Apply the lateral convolution to match the number of channels\n",
    "            lateral_x = self.lateral_convs[i](features[i])\n",
    "            \n",
    "            # Add the upsampled feature map to the current feature map\n",
    "            x = x + lateral_x\n",
    "            \n",
    "            # Append the processed feature map to the output list\n",
    "            bottom_up_features.append(x)\n",
    "        \n",
    "        return bottom_up_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f810f5-f100-4136-aa6b-9664046820e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcf60ed-e777-4b3e-bb27-018bbed23f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveFeaturePooling(nn.Module):\n",
    "    def __init__(self, output_size):\n",
    "        \"\"\"\n",
    "        :param output_size: The target output size (e.g., (1, 1) for global pooling or (7, 7) for a detailed representation)\n",
    "        \"\"\"\n",
    "        super(AdaptiveFeaturePooling, self).__init__()\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: Input tensor (batch_size, channels, height, width)\n",
    "        :return: Pooled output of the target size\n",
    "        \"\"\"\n",
    "        # Apply adaptive average pooling\n",
    "        x = F.adaptive_avg_pool2d(x, self.output_size)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4f626c-8393-4771-8478-cd913ad88c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dead488-d9f9-4327-afae-a042c14f9a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoxBranch(nn.Module):\n",
    "    def __init__(self, in_channels, num_anchors):\n",
    "        \"\"\"\n",
    "        :param in_channels: Number of input channels from the feature map.\n",
    "        :param num_anchors: Number of anchor boxes per location.\n",
    "        \"\"\"\n",
    "        super(BoxBranch, self).__init__()\n",
    "\n",
    "        # Convolutional layers to process the feature map before regressing bounding boxes\n",
    "        self.conv1 = nn.Conv2d(in_channels, 256, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Final layer to predict bounding box coordinates (dx, dy, dw, dh)\n",
    "        # For each anchor, we predict 4 values (dx, dy, dw, dh)\n",
    "        self.box_pred = nn.Conv2d(256, num_anchors * 4, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: Feature map from the backbone or a subsequent layer (batch_size, channels, height, width)\n",
    "        :return: Predicted bounding box offsets (dx, dy, dw, dh) for each anchor.\n",
    "        \"\"\"\n",
    "        # Pass through convolutional layers\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "\n",
    "        # Output bounding box predictions (dx, dy, dw, dh)\n",
    "        box_pred = self.box_pred(x)\n",
    "\n",
    "        # Reshape the predictions: (batch_size, num_anchors*4, height, width)\n",
    "        # num_anchors is the number of anchor boxes per spatial location\n",
    "        box_pred = box_pred.permute(0, 2, 3, 1).contiguous()\n",
    "        \n",
    "        # Reshape to (batch_size, height, width, num_anchors, 4)\n",
    "        # This makes it easier to match with the anchors for bounding box regression\n",
    "        box_pred = box_pred.view(x.size(0), x.size(2), x.size(3), -1, 4)\n",
    "        \n",
    "        return box_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf8475d-c453-4a02-bc17-f8eb899a41b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
