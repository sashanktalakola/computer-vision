{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ae76ec-e7d1-4e41-be68-ac3827648e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e6b254-0c49-4fe2-8ffc-e8ae8773d875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "class FourierFeatureEmbedding2D(torch.nn.Module):\n",
    "    def __init__(self, img_size, patch_size, num_frequencies=10, embedding_dim=768, scale=1.0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img_size (tuple): The size of the input image (height, width).\n",
    "            patch_size (tuple): The size of each patch (height, width).\n",
    "            num_frequencies (int): Number of frequency bands to use for sine/cosine.\n",
    "            embedding_dim (int): The dimension of the patch embeddings (usually 768 or 1024 for ViT).\n",
    "            scale (float): Scaling factor for the input coordinates.\n",
    "        \"\"\"\n",
    "        super(FourierFeatureEmbedding2D, self).__init__()\n",
    "        \n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.num_frequencies = num_frequencies\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.scale = scale\n",
    "        \n",
    "        # Calculate number of patches along each axis (height and width)\n",
    "        self.num_patches_y = img_size[0] // patch_size[0]\n",
    "        self.num_patches_x = img_size[1] // patch_size[1]\n",
    "        \n",
    "        # Frequencies: logarithmic spacing between 0 and 2*pi\n",
    "        self.frequencies = torch.logspace(0, math.log10(2 * math.pi), num_frequencies, base=10)\n",
    "\n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        Generate the 2D Fourier feature positional embeddings for each patch.\n",
    "        \n",
    "        Returns:\n",
    "            tensor: Positional embeddings for each patch (shape: [num_patches, embedding_dim])\n",
    "        \"\"\"\n",
    "        # Generate patch grid coordinates\n",
    "        y_coords = torch.arange(self.num_patches_y).float()\n",
    "        x_coords = torch.arange(self.num_patches_x).float()\n",
    "        \n",
    "        # Create meshgrid of patch coordinates\n",
    "        grid_y, grid_x = torch.meshgrid(y_coords, x_coords)\n",
    "        \n",
    "        # Normalize to range [0, 1] (optional scaling)\n",
    "        grid_y = grid_y / (self.num_patches_y - 1)\n",
    "        grid_x = grid_x / (self.num_patches_x - 1)\n",
    "        \n",
    "        # Stack coordinates into a 2D grid of shape [num_patches, 2]\n",
    "        positions = torch.stack([grid_x.flatten(), grid_y.flatten()], dim=-1)  # Shape: [num_patches, 2]\n",
    "        \n",
    "        # Apply Fourier feature transformation\n",
    "        embeddings = []\n",
    "\n",
    "        for freq in self.frequencies:\n",
    "            # Apply sine and cosine transformations to both x and y coordinates\n",
    "            embeddings.append(torch.sin(freq * positions[:, 0]))\n",
    "            embeddings.append(torch.cos(freq * positions[:, 0]))\n",
    "            embeddings.append(torch.sin(freq * positions[:, 1]))\n",
    "            embeddings.append(torch.cos(freq * positions[:, 1]))\n",
    "\n",
    "        # Concatenate all sine/cosine embeddings, result will have shape [num_patches, 4 * num_frequencies]\n",
    "        embeddings = torch.stack(embeddings, dim=-1)\n",
    "\n",
    "        # Flatten the embeddings to match the desired embedding dimension\n",
    "        embeddings = embeddings.view(self.num_patches_y * self.num_patches_x, -1)  # Shape: [num_patches, 4 * num_frequencies]\n",
    "\n",
    "        return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5001422-9924-43be-a399-a63d70b14140",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a385aff-c614-4965-8102-8fdc0f625c6f",
   "metadata": {},
   "source": [
    "If PE embedding dim does not match patch embedding dim -\n",
    "\n",
    "<code>\n",
    "# If the resulting embedding dimension does not match the patch embedding size, we can apply a linear transformation\n",
    "if embeddings.size(1) != self.embedding_dim:\n",
    "    # Linear transformation to match embedding dimension\n",
    "    self.linear = torch.nn.Linear(embeddings.size(1), self.embedding_dim)\n",
    "    embeddings = self.linear(embeddings)\n",
    "</code>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
